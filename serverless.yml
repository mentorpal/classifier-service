##
## This software is Copyright ©️ 2020 The University of Southern California. All Rights Reserved. 
## Permission to use, copy, modify, and distribute this software and its documentation for educational, research and non-profit purposes, without fee, and without a written agreement is hereby granted, provided that the above copyright notice and subject to the full license file found in the root of this software deliverable. Permission to make commercial use of this software may be obtained by contacting:  USC Stevens Center for Innovation University of Southern California 1150 S. Olive Street, Suite 2300, Los Angeles, CA 90115, USA Email: accounting@stevens.usc.edu
##
## The full terms of this copyright and license should always be found in the root directory of this software deliverable as "license.txt" and if these terms are not found with this software, please contact the USC Stevens Center for the full license.
##

# This file is the main config file for your service.
#
# For full config options, check the docs:
#    docs.serverless.com
#

service: mentor-classifier-service

# pin the service to only deploy with a specific Serverless version
frameworkVersion: '2'
variablesResolutionMode: 20210326

custom:
  stages:
    offline:
      LOG_LEVEL: 'trace'
      GRAPHQL_ENDPOINT: 'http://127.0.0.1:3001/graphql'
      IS_SENTRY_ENABLED: false
    dev:
      # TODO cors
      LOG_LEVEL: 'trace'
      IS_SENTRY_ENABLED: false
      # v2 is hardcoded, we could use fallback stages instead
      GRAPHQL_ENDPOINT: 'https://v2.mentorpal.org/graphql'
      API_SECRET: '${ssm:/mentorpal/v2/shared/api_secret}'
      ALERT_SNS_ARN: ${ssm:/mentorpal/v2/shared/sns_alert_topic_arn}
    qa:
      LOG_LEVEL: 'debug'
      IS_SENTRY_ENABLED: true
      GRAPHQL_ENDPOINT: 'https://v2.mentorpal.org/graphql'
      API_SECRET: '${ssm:/mentorpal/v2/shared/api_secret}'
      ALERT_SNS_ARN: ${ssm:/mentorpal/v2/shared/sns_alert_topic_arn}
    prod:
      LOG_LEVEL: 'info'
      IS_SENTRY_ENABLED: true
      GRAPHQL_ENDPOINT: 'https://careerfair.mentorpal.org/graphql'


provider:
  name: aws
  stage: ${opt:stage, 'dev'} # stage is dev unless otherwise specified with --stage flag
  lambdaHashingVersion: 20201221
  stackTags:
    ENVIRONMENT: ${self:provider.stage}
    PROJECT: ${self:service}-${self:provider.stage}
    REPOSITORY: mentor-classifier-service
  ecr:
    # In this section you can define images that will be built locally and uploaded to ECR
    images:
      train:
        path: ./
        file: Dockerfile
  endpointType: regional
  tracing:
    lambda: true
  logRetentionInDays: 30
  logs:
      # Enables HTTP access logs (default: true)
      accessLogging: true
      # # Log format to use for access logs
      # format: 'requestId: $context.requestId'
      # Enable execution logging (default: true)
      executionLogging: true
      level: INFO  # INFO or ERROR
      # Log full requests/responses for execution logging (default: true)
      fullExecutionData: true
  region: us-east-1
  # architecture: x86_64 # if necessary
  environment:
    STAGE: ${self:provider.stage}
    PYTHON_ENV: careerfair-${self:provider.stage}
    GRAPHQL_ENDPOINT: ${self:custom.stages.${self:provider.stage}.GRAPHQL_ENDPOINT}
    API_SECRET: ${self:custom.stages.${self:provider.stage}.API_SECRET}
    IS_SENTRY_ENABLED: ${self:custom.stages.${self:provider.stage}.IS_SENTRY_ENABLED}
    SENTRY_DSN_MENTOR_CLASSIFIER: '${ssm:/mentorpal/upload/sentry_dsn}'
    SHARED_ROOT: '/app/shared' # as defined in Dockerfile

# TODO
#  iam:
#    role:
#      statements:
#        - Effect: "Allow"
#          Action:
#            - "s3:ListBucket"
#          Resource: { "Fn::Join" : ["", ["arn:aws:s3:::", { "Ref" : "ServerlessDeploymentBucket" } ] ]  }
#        - Effect: "Allow"
#          Action:
#            - "s3:PutObject"
#          Resource:
#            Fn::Join:
#              - ""
#              - - "arn:aws:s3:::"
#                - "Ref" : "ServerlessDeploymentBucket"
#                - "/*"

# package:
# #  individually: false
#  patterns:
#     # exclude everything:
#      - '!./**'
#     # and then add back in only the files we need:
#      - '*.py'

functions:
  http_train:
    image:
      name: train
    memorySize: 8192
    timeout: 30
    events:
      - httpApi:
          path: /train
          method: get
          cors: true
  http_answer:
    image:
      name: train
    memorySize: 1024
    timeout: 20
    events:
      - httpApi:
          path: /questions
          method: get
          cors: true
  http_training_data:
    image:
      name: train
    memorySize: 1024
    timeout: 20
    cors: true
    events:
      - httpApi:
          path: /trainingdata
          method: get
          cors: true

#    The following are a few example events you can configure
#    NOTE: Please make sure to change your handler code to work with those events
#    Check the event documentation for details
#    events:
#      - httpApi:
#          path: /users/create
#          method: get
#      - websocket: $connect
#      - s3: ${env:BUCKET}
#      - schedule: rate(10 minutes)
#      - sns: greeter-topic
#      - stream: arn:aws:dynamodb:region:XXXXXX:table/foo/stream/1970-01-01T00:00:00.000
#      - alexaSkill: amzn1.ask.skill.xx-xx-xx-xx
#      - alexaSmartHome: amzn1.ask.skill.xx-xx-xx-xx
#      - iot:
#          sql: "SELECT * FROM 'some_topic'"
#      - cloudwatchEvent:
#          event:
#            source:
#              - "aws.ec2"
#            detail-type:
#              - "EC2 Instance State-change Notification"
#            detail:
#              state:
#                - pending
#      - cloudwatchLog: '/aws/lambda/hello'
#      - cognitoUserPool:
#          pool: MyUserPool
#          trigger: PreSignUp
#      - alb:
#          listenerArn: arn:aws:elasticloadbalancing:us-east-1:XXXXXX:listener/app/my-load-balancer/50dc6c495c0c9188/
#          priority: 1
#          conditions:
#            host: example.com
#            path: /hello

#    Define function environment variables here
#    environment:
#      variable2: value2

# you can add CloudFormation resource templates here
#resources:
#  Resources:
#    NewResource:
#      Type: AWS::S3::Bucket
#      Properties:
#        BucketName: my-new-bucket
#  Outputs:
#     NewOutput:
#       Description: "Description for the output"
#       Value: "Some output value"
